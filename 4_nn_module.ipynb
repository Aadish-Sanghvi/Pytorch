{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch.nn module in PyTorch is a core library that provides a wide array of classes and\n",
    "functions designed to help developers build neural networks efficiently and effectively. It\n",
    "abstracts the complexity of creating and training neural networks by offering pre-built layers,\n",
    "loss functions, activation functions, and other utilities, enabling you to focus on designing and\n",
    "experimenting with model architectures.\n",
    "\n",
    "\n",
    "Key Components of torch.nn:\n",
    "1. Modules (Layers):\n",
    "- nn.Module: The base class for all neural network modules. Your custom models and\n",
    "layers should subclass this class.\n",
    "\n",
    "- Common Layers: Includes layers like nn.Linear (fully connected layer), nn.Conv2d (convolutional layer), nn.LSTM (recurrent layer), and many others.\n",
    "\n",
    "2. Activation Functions:\n",
    "- Functions like nn.ReLU, nn.Sigmoid, and nn.Tanh introduce non-linearities to the model, allowing it to learn complex patterns.\n",
    "\n",
    "3. Loss Functions:\n",
    "- Provides loss functions such as nn.CrossEntropyLoss, nn.MSELoss, and nn.NLLLoss to quantify the difference between the model's predictions and the actual targets.\n",
    "\n",
    "4. Container Modules:\n",
    "- nn.Sequential: A sequential container to stack layers in order.\n",
    "\n",
    "5. Regularization and Dropout:\n",
    "- Layers like nn.Dropout and nn.BatchNorm2d help prevent overfitting and improve the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1. Simple Linear Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model class \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Model1, self).__init__()  # Call parent constructor\n",
    "        self.linear = nn.Linear(num_features, 1) # takes input and output number of features.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3891],\n",
       "        [0.5536],\n",
       "        [0.7578],\n",
       "        [0.4990],\n",
       "        [0.5463],\n",
       "        [0.5466],\n",
       "        [0.5177],\n",
       "        [0.5342],\n",
       "        [0.2421],\n",
       "        [0.5156]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset \n",
    "features = torch.randn(10, 5) # generates random values from a normal distribution.\n",
    "\n",
    "# Create model \n",
    "model1 = Model1(features.shape[1])\n",
    "\n",
    "# Call model for forward pass \n",
    "model1(features)  # Calls forward() automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1262], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show model weights\n",
    "model1.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model1                                   [10, 1]                   --\n",
       "├─Linear: 1-1                            [10, 1]                   6\n",
       "├─Sigmoid: 1-2                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 6\n",
       "Trainable params: 6\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model1, (10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2. Hidden Layer Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_features, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4756],\n",
       "        [0.4888],\n",
       "        [0.4402],\n",
       "        [0.4957],\n",
       "        [0.4900],\n",
       "        [0.5027],\n",
       "        [0.5071],\n",
       "        [0.4393],\n",
       "        [0.4318],\n",
       "        [0.5099]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset \n",
    "features = torch.randn(10, 5)\n",
    "\n",
    "# Create model \n",
    "model2 = Model2(features.shape[1]) # passing the columns\n",
    "\n",
    "# Call model for forward pass \n",
    "model2(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1587,  0.2619,  0.4098, -0.1845, -0.0357],\n",
       "        [ 0.3881, -0.4406, -0.2615, -0.3614,  0.0019],\n",
       "        [ 0.4159, -0.3444,  0.1603, -0.3098, -0.1744]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4003,  0.3865, -0.0358], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.linear1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model2                                   [10, 1]                   --\n",
       "├─Linear: 1-1                            [10, 3]                   18\n",
       "├─ReLU: 1-2                              [10, 3]                   --\n",
       "├─Linear: 1-3                            [10, 1]                   4\n",
       "├─Sigmoid: 1-4                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 22\n",
       "Trainable params: 22\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2, (10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3. Using Container*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5494],\n",
       "        [0.4428],\n",
       "        [0.5302],\n",
       "        [0.4572],\n",
       "        [0.4635],\n",
       "        [0.4635],\n",
       "        [0.4635],\n",
       "        [0.4500],\n",
       "        [0.4635],\n",
       "        [0.4679]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset \n",
    "features = torch.randn(10, 5)\n",
    "\n",
    "# Create model \n",
    "model3 = Model3(features.shape[1])\n",
    "\n",
    "# Call model for forward pass \n",
    "model3(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
